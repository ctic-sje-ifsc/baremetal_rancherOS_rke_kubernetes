---
nodes:
- address: nodenuvem1.sj.ifsc.edu.br
  role: [controlplane,worker,etcd]
  hostname_override: nodenuvem1
  user: rancher
  ssh_key_path: ~/.ssh/id_rsa
- address: nodenuvem2.sj.ifsc.edu.br
  role: [controlplane,worker,etcd]
  hostname_override: nodenuvem2
  user: rancher
  ssh_key_path: ~/.ssh/id_rsa
- address: nodenuvem3.sj.ifsc.edu.br
  role: [controlplane,worker,etcd]
  hostname_override: nodenuvem3
  user: rancher
  ssh_key_path: ~/.ssh/id_rsa
# - address: nodenuvem4.sj.ifsc.edu.br
#   role: [worker]
#   hostname_override: nodenuvem4
#   user: rancher
#   ssh_key_path: ~/.ssh/id_rsa
- address: nodenuvem5.sj.ifsc.edu.br
  role: [worker]
  hostname_override: nodenuvem5
  user: rancher
  ssh_key_path: ~/.ssh/id_rsa

network:
  plugin: flannel

services:
  etcd:
    snapshot: true
    creation: 5h0s
    retention: 48h

# Antes estavamos utilizando a flag 'kubernetes_version: "v1.8.11-rancher2-1"', e sem o system_images. 
# e por algum motivo com a atualização do rke ele ignorou e atualizou o kubernetes para hyperkube:v1.11.1-rancher1. 
# Segunto https://rancher.com/docs/rke/v0.1.x/en/config-options/#kubernetes-version o system_images é precedente ao kubernetes_version. 
# E segundo https://rancher.com/docs/rke/v0.1.x/en/upgrades/ não é possível fazer downgrade, então por hora fixei nessa versão.
system_images:
    kubernetes: rancher/hyperkube:v1.11.6-rancher1

authentication:
  strategy: x509
  sans:
  - "api-cloud.sj.ifsc.edu.br"

ssh_key_path: ~/.ssh/id_rsa

addons: |-
  ---
  kind: Namespace
  apiVersion: v1
  metadata:
    name: cattle-system
  ---
  kind: ServiceAccount
  apiVersion: v1
  metadata:
    name: cattle-admin
    namespace: cattle-system
  ---
  kind: ClusterRoleBinding
  apiVersion: rbac.authorization.k8s.io/v1
  metadata:
    name: cattle-crb
    namespace: cattle-system
  subjects:
  - kind: ServiceAccount
    name: cattle-admin
    namespace: cattle-system
  roleRef:
    kind: ClusterRole
    name: cluster-admin
    apiGroup: rbac.authorization.k8s.io
  ---
  apiVersion: v1
  kind: Secret
  metadata:
    name: cattle-keys-ingress
    namespace: cattle-system
  type: Opaque
  data:
    tls.crt: "cat tls.crt | base64 | tr -d '\n'"
    tls.key: "cat tls.key | base64 | tr -d '\n'"
  ---
  apiVersion: v1
  kind: Service
  metadata:
    namespace: cattle-system
    name: cattle-service
    labels:
      app: cattle
  spec:
    ports:
    - port: 80
      targetPort: 80
      protocol: TCP
      name: http
    - port: 443
      targetPort: 443
      protocol: TCP
      name: https
    selector:
      app: cattle
  ---
  apiVersion: extensions/v1beta1
  kind: Ingress
  metadata:
    namespace: cattle-system
    name: cattle-ingress-http
    annotations:
      nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
      nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
      nginx.ingress.kubernetes.io/proxy-send-timeout: "1800"
  spec:
    rules:
    - host: projetos.sj.ifsc.edu.br
      http:
        paths:
        - backend:
            serviceName: cattle-service
            servicePort: 80
    tls:
    - secretName: cattle-keys-ingress
      hosts:
      - projetos.sj.ifsc.edu.br
  ---
  kind: Deployment
  apiVersion: extensions/v1beta1
  metadata:
    namespace: cattle-system
    name: cattle
  spec:
    replicas: 1
    template:
      metadata:
        labels:
          app: cattle
      spec:
        serviceAccountName: cattle-admin
        containers:
        - image: rancher/rancher:latest
          imagePullPolicy: Always
          name: cattle-server
          ports:
          - containerPort: 80
            protocol: TCP
          - containerPort: 443
            protocol: TCP