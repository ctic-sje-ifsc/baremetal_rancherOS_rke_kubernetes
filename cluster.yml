---
nodes:
- address: nodenuvem1.sj.ifsc.edu.br
  role: [controlplane,worker,etcd]
  hostname_override: nodenuvem1
  user: rancher
  ssh_key_path: ~/.ssh/id_rsa
- address: nodenuvem2.sj.ifsc.edu.br
  role: [controlplane,worker,etcd]
  hostname_override: nodenuvem2
  user: rancher
  ssh_key_path: ~/.ssh/id_rsa
- address: nodenuvem3.sj.ifsc.edu.br
  role: [controlplane,worker,etcd]
  hostname_override: nodenuvem3
  user: rancher
  ssh_key_path: ~/.ssh/id_rsa
# - address: nodenuvem4.sj.ifsc.edu.br
#   role: [worker]
#   hostname_override: nodenuvem4
#   user: rancher
#   ssh_key_path: ~/.ssh/id_rsa
- address: nodenuvem5.sj.ifsc.edu.br
  role: [worker]
  hostname_override: nodenuvem5
  user: rancher
  ssh_key_path: ~/.ssh/id_rsa

network:
  plugin: flannel

services:
  etcd:
    snapshot: true
    creation: 5h0s
    retention: 48h

# Antes estavamos utilizando a flag 'kubernetes_version: "v1.8.11-rancher2-1"', e sem o system_images. 
# e por algum motivo com a atualização do rke ele ignorou e atualizou o kubernetes para hyperkube:v1.11.1-rancher1. 
# Segunto https://rancher.com/docs/rke/v0.1.x/en/config-options/#kubernetes-version o system_images é precedente ao kubernetes_version. 
# E segundo https://rancher.com/docs/rke/v0.1.x/en/upgrades/ não é possível fazer downgrade, então por hora fixei nessa versão.
system_images:
    kubernetes: rancher/hyperkube:v1.11.6-rancher1

authentication:
  strategy: x509
  sans:
  - "api-cloud.sj.ifsc.edu.br"

ssh_key_path: ~/.ssh/id_rsa

addons: |-
