---
nodes:
- address: nodenuvem1.sj.ifsc.edu.br
  role: [controlplane,worker,etcd]
  hostname_override: nodenuvem1
  user: rancher
  ssh_key_path: ~/.ssh/id_rsa
- address: nodenuvem2.sj.ifsc.edu.br
  role: [controlplane,worker,etcd]
  hostname_override: nodenuvem2
  user: rancher
  ssh_key_path: ~/.ssh/id_rsa
- address: nodenuvem3.sj.ifsc.edu.br
  role: [controlplane,worker,etcd]
  hostname_override: nodenuvem3
  user: rancher
  ssh_key_path: ~/.ssh/id_rsa
- address: nodenuvem4.sj.ifsc.edu.br
  role: [worker]
  hostname_override: nodenuvem4
  user: rancher
  ssh_key_path: ~/.ssh/id_rsa
- address: nodenuvem5.sj.ifsc.edu.br
  role: [worker]
  hostname_override: nodenuvem5
  user: rancher
  ssh_key_path: ~/.ssh/id_rsa

network:
  plugin: flannel

# Para habilitar suporte a HPA com metrics-server:
# - https://github.com/rancher/rancher/issues/12711 
# - ttps://gist.github.com/superseb/90527bd079feac17f379964f50769e28
# - https://kubernetes.io/docs/tasks/access-kubernetes-api/configure-aggregation-layer/

services:
  kube-api:
    extra_args:
      proxy-client-cert-file: "/etc/kubernetes/ssl/kube-proxy.pem"
      proxy-client-key-file: "/etc/kubernetes/ssl/kube-proxy-key.pem"
      requestheader-client-ca-file: "/etc/kubernetes/ssl/kube-ca.pem"
      requestheader-extra-headers-prefix: "X-Remote-Extra-"
      requestheader-group-headers: "X-Remote-Group"
      requestheader-username-headers: "X-Remote-User"
    podSecurityPolicy: false
  kubelet:
    extra_args:
      authentication-token-webhook: "true"
      read-only-port: "10255"
  kube-controller:
    extra_args:
      horizontal-pod-autoscaler-use-rest-clients: true

  etcd:
    snapshot: true
    creation: 1h
    retention: 48h

# Antes estavamos utilizando a flag 'kubernetes_version: "v1.8.11-rancher2-1"', e sem o system_images. 
# e por algum motivo com a atualização do rke ele ignorou e atualizou o kubernetes para hyperkube:v1.11.1-rancher1. 
# Segunto https://rancher.com/docs/rke/v0.1.x/en/config-options/#kubernetes-version o system_images é precedente ao kubernetes_version. 
# E segundo https://rancher.com/docs/rke/v0.1.x/en/upgrades/ não é possível fazer downgrade, então por hora fixei nessa versão.
system_images:
    kubernetes: rancher/hyperkube:v1.11.1-rancher1

authentication:
  strategy: x509
  sans:
  - "api-cloud.sj.ifsc.edu.br"

ssh_key_path: ~/.ssh/id_rsa

addons: |-
  ---
  kind: Namespace
  apiVersion: v1
  metadata:
    name: cattle-system
  ---
  kind: ServiceAccount
  apiVersion: v1
  metadata:
    name: cattle-admin
    namespace: cattle-system
  ---
  kind: ClusterRoleBinding
  apiVersion: rbac.authorization.k8s.io/v1
  metadata:
    name: cattle-crb
    namespace: cattle-system
  subjects:
  - kind: ServiceAccount
    name: cattle-admin
    namespace: cattle-system
  roleRef:
    kind: ClusterRole
    name: cluster-admin
    apiGroup: rbac.authorization.k8s.io
  ---
  apiVersion: v1
  kind: Secret
  metadata:
    name: cattle-keys-ingress
    namespace: cattle-system
  type: Opaque
  data:
    tls.crt: "cat tls.crt | base64 | tr -d '\n'"
    tls.key: "cat tls.key | base64 | tr -d '\n'"
  ---
  apiVersion: v1
  kind: Service
  metadata:
    namespace: cattle-system
    name: cattle-service
    labels:
      app: cattle
  spec:
    ports:
    - port: 80
      targetPort: 80
      protocol: TCP
      name: http
    - port: 443
      targetPort: 443
      protocol: TCP
      name: https
    selector:
      app: cattle
  ---
  apiVersion: extensions/v1beta1
  kind: Ingress
  metadata:
    namespace: cattle-system
    name: cattle-ingress-http
    annotations:
      nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
      nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
      nginx.ingress.kubernetes.io/proxy-send-timeout: "1800"
  spec:
    rules:
    - host: projetos.sj.ifsc.edu.br
      http:
        paths:
        - backend:
            serviceName: cattle-service
            servicePort: 80
    tls:
    - secretName: cattle-keys-ingress
      hosts:
      - projetos.sj.ifsc.edu.br
  ---
  kind: Deployment
  apiVersion: extensions/v1beta1
  metadata:
    namespace: cattle-system
    name: cattle
  spec:
    replicas: 1
    template:
      metadata:
        labels:
          app: cattle
      spec:
        serviceAccountName: cattle-admin
        containers:
        - image: rancher/rancher:latest
          imagePullPolicy: Always
          name: cattle-server
          ports:
          - containerPort: 80
            protocol: TCP
          - containerPort: 443
            protocol: TCP

# Adicionando o Metrics Server 
# - https://github.com/kubernetes/kops/tree/master/addons/metrics-server
# - https://github.com/kubernetes-incubator/metrics-server

addons_include:
  - https://raw.githubusercontent.com/kubernetes/kops/master/addons/metrics-server/v1.8.x.yaml